{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 748,
     "status": "ok",
     "timestamp": 1629872336072,
     "user": {
      "displayName": "Indrajeet kaur",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiVZu8J9bd9Yqar73icR1fv2cMZcNPBoV_zInd5ig=s64",
      "userId": "05234845784652846916"
     },
     "user_tz": -330
    },
    "id": "4M7Pdo_y07_n"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "arr = np.array([['from', 'wheres', 'my', 'thing', 'subject', 'what', 'car', 'is', 'this', 'nntp', 'posting', 'host', 'rac', 'wam', 'umd', 'edu', 'organization', 'university', 'of', 'maryland', 'college', 'park', 'lines'],\n",
    " ['was', 'wondering', 'if', 'anyone', 'out', 'there', 'could', 'enlighten', 'me', 'on', 'this', 'car', 'saw', 'the', 'other', 'day', 'it', 'was', 'door', 'sports', 'car', 'looked', 'to'], \n",
    " ['be', 'from', 'the', 'late', 'early', 'it', 'was', 'called', 'bricklin', 'the', 'doors', 'were', 'really', 'small', 'in', 'addition', 'the', 'front', 'bumper', 'was', 'separate', 'from', 'the'], \n",
    " ['rest', 'of', 'the', 'body', 'this', 'is', 'all', 'know', 'if', 'anyone', 'can', 'tellme', 'model', 'name', 'engine', 'specs', 'years', 'of', 'production', 'where', 'this', 'car', 'is'], \n",
    " ['made', 'history', 'or', 'whatever', 'info', 'you', 'have', 'on', 'this', 'funky', 'looking', 'car', 'please', 'mail', 'thanks', 'il', 'brought', 'to', 'you', 'by', 'your', 'neighborhood', 'lerxst']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 472,
     "status": "ok",
     "timestamp": 1629872338682,
     "user": {
      "displayName": "Indrajeet kaur",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiVZu8J9bd9Yqar73icR1fv2cMZcNPBoV_zInd5ig=s64",
      "userId": "05234845784652846916"
     },
     "user_tz": -330
    },
    "id": "AMH8rQ3f1LBS"
   },
   "outputs": [],
   "source": [
    "arr1 = np.array([['from', 'guy', 'kuo', 'subject',  'clock', 'poll', 'final', 'summary', 'final', 'call', 'for', 'si', 'reports', 'keywords', 'acceleration', 'clock', 'upgrade', 'article', 'shelley', 'qvfo', 'innc', 'organization', 'university', 'of', 'washington', 'lines', 'nntp', 'posting', 'host', 'carson', 'washington', 'edu', 'fair', 'number', 'of', 'brave', 'souls', 'who', 'upgraded', 'their', 'si', 'clock', 'oscillator', 'have', 'shared', 'their', 'experiences', 'for', 'this', 'poll', 'please', 'send', 'brief', 'message', 'detailing', 'your', 'experiences', 'with', 'the', 'procedure', 'top', 'speed', 'attained', 'rated', 'speed', 'add', 'cards', 'adapters', 'heat', 'sinks', 'hour', 'of', 'usage', 'per', 'day', 'floppy', 'disk', 'functionality', 'with', 'and', 'floppies', 'are', 'especially', 'requested', 'will', 'be', 'summarizing', 'in', 'the', 'next', 'two', 'days', 'so', 'please', 'add', 'to', 'the', 'network', 'knowledge', 'base', 'if', 'you', 'have', 'done', 'the', 'clock', 'upgrade', 'and', 'havent', 'answered', 'this', 'poll', 'thanks', 'guy', 'kuo']])\n",
    "arr1 = np.reshape(arr1,(5,23))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "executionInfo": {
     "elapsed": 1331,
     "status": "ok",
     "timestamp": 1629872329369,
     "user": {
      "displayName": "Indrajeet kaur",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiVZu8J9bd9Yqar73icR1fv2cMZcNPBoV_zInd5ig=s64",
      "userId": "05234845784652846916"
     },
     "user_tz": -330
    },
    "id": "QcDNtvOx1gN3"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "from pprint import pprint\n",
    "\n",
    "import gensim.corpora as corpora\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "from gensim.models import CoherenceModel\n",
    "from pprint import pprint\n",
    "\n",
    "\n",
    "class fit_lda:\n",
    "    \n",
    "    # To convert the 2d array data into list\n",
    "    def convert_to_list(self,inp1, inp2):\n",
    "        data_words1 = inp1.tolist()\n",
    "        data_words2= inp2.tolist()\n",
    "        return data_words1,data_words2\n",
    "    \n",
    "    \n",
    "    #To create corpus and id2word\n",
    "    def data_processing(self,data_words):\n",
    "        id2word = corpora.Dictionary(data_words)\n",
    "        texts = data_words\n",
    "        corpus = [id2word.doc2bow(text) for text in texts]\n",
    "        return corpus,id2word\n",
    "    \n",
    "    \n",
    "    # To fit the LDA model\n",
    "    def Lda_fit(self,data_words,corpus1,id2word1,n,r,c,p):\n",
    "        lda_model = gensim.models.LdaMulticore(corpus=corpus1,\n",
    "                                       id2word=id2word1,\n",
    "                                       num_topics=n, \n",
    "                                       random_state=r,\n",
    "                                       chunksize=c,\n",
    "                                       passes=p,\n",
    "                                       per_word_topics=True)\n",
    "        pprint(lda_model.print_topics())\n",
    "        return lda_model\n",
    "    \n",
    "    \n",
    "    # To find the coherence score\n",
    "    def coherence(self,data_words,id2word1,modelfit):\n",
    "        coherence_model_lda = CoherenceModel(model=modelfit, texts=data_words, dictionary=id2word1, coherence='c_v')\n",
    "        coherence_lda = coherence_model_lda.get_coherence()\n",
    "        print('*****************************************************************************************************************************')\n",
    "        print('\\nCoherence Score of the trained LDA model : ', coherence_lda)\n",
    "        print('\\n*****************************************************************************************************************************')\n",
    "    \n",
    "    \n",
    "    #To compute the coherence score of different LDA model obtained from multiple number of topics\n",
    "    def compute_coherence_values(self,data_words,corpus1,id2word1):\n",
    "        limit=50; start=2; step=7;\n",
    "        coherence_values = []\n",
    "        model_list = []\n",
    "        for num_topics in range(start, limit, step):\n",
    "          model=gensim.models.LdaMulticore(corpus=corpus1, id2word=id2word1, num_topics=num_topics)\n",
    "          model_list.append(model)\n",
    "          coherencemodel = CoherenceModel(model=model, texts=data_words, dictionary=id2word1, coherence='c_v')\n",
    "          coherence_values.append(coherencemodel.get_coherence())\n",
    "       \n",
    "        return model_list, coherence_values\n",
    "    \n",
    "    \n",
    "    # To find the best coherence score and optimal number of topics for the best coherence score of the best LDA model\n",
    "    def best_model_lda(self,data_words,model_list, coherence_values):\n",
    "        range_topics = range(2, 50, 7)\n",
    "        best_coherence= max(coherence_values)  \n",
    "        Topic_best_coherence = range_topics[coherence_values.index(best_coherence)] \n",
    "        print(\"\\nCoherence score of the best LDA model : \", best_coherence)\n",
    "        print(\"Optimal number of topics of the best LDA model : \", Topic_best_coherence)\n",
    "        return best_coherence, Topic_best_coherence\n",
    "    \n",
    "    \n",
    "    def main_func(self,inp1, inp2,num_topic,random_state, chunksize, passes):\n",
    "        data_words,data_wordsnew = self.convert_to_list(inp1, inp2)\n",
    "        \n",
    "        corpus_o,id2word_o= self.data_processing(data_words)\n",
    "        corpus_new,id2word_new= self.data_processing(data_wordsnew)\n",
    "        # Training for the first time\n",
    "        print(\"****TRAINING A LDA MODEL****\")\n",
    "        modelfit = self.Lda_fit(data_words,corpus_o,id2word_o,num_topic,random_state, chunksize, passes)\n",
    "        self.coherence(data_words,id2word_o,modelfit)\n",
    "\n",
    "        print(\"\\n****TRAINING THE LDA MODEL FOR MULTIPLE NUMBER OF TOPICS****\")\n",
    "        model_list, coherence_values = self.compute_coherence_values(data_words,corpus_o,id2word_o)\n",
    "\n",
    "        print('\\n*****************************************************************************************************************************')\n",
    "        print(\"\\n****CALCULATING THE COHERENCE SCORE AND OPTIMAL NUMBER OF TOPICS FOR THE BEST MODEL OBTAINED****\")\n",
    "        best_coherence, Topic_best_coherence = self.best_model_lda(data_words,model_list, coherence_values)\n",
    "        print('\\n*****************************************************************************************************************************')\n",
    "        #new model\n",
    "        print('\\n****PREDICTING NEW INSTANCES BASED ON BEST LDA MODEL****')\n",
    "        self.Lda_fit(data_wordsnew,corpus_new,id2word_new,Topic_best_coherence,random_state, chunksize, passes)\n",
    "\n",
    "\n",
    "\n",
    "   \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5588,
     "status": "ok",
     "timestamp": 1629872352458,
     "user": {
      "displayName": "Indrajeet kaur",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GiVZu8J9bd9Yqar73icR1fv2cMZcNPBoV_zInd5ig=s64",
      "userId": "05234845784652846916"
     },
     "user_tz": -330
    },
    "id": "75a2UHx_rUYV",
    "outputId": "eb6b0021-f944-4def-b3fc-e8a0eaba983b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****TRAINING A LDA MODEL****\n",
      "[(0,\n",
      "  '0.012*\"you\" + 0.012*\"whatever\" + 0.012*\"info\" + 0.012*\"car\" + '\n",
      "  '0.012*\"neighborhood\" + 0.012*\"your\" + 0.012*\"by\" + 0.012*\"funky\" + '\n",
      "  '0.012*\"on\" + 0.012*\"thanks\"'),\n",
      " (1,\n",
      "  '0.012*\"this\" + 0.012*\"of\" + 0.012*\"is\" + 0.012*\"car\" + 0.012*\"the\" + '\n",
      "  '0.012*\"anyone\" + 0.012*\"if\" + 0.012*\"engine\" + 0.012*\"years\" + '\n",
      "  '0.012*\"model\"'),\n",
      " (2,\n",
      "  '0.060*\"the\" + 0.049*\"was\" + 0.037*\"from\" + 0.037*\"car\" + 0.025*\"it\" + '\n",
      "  '0.025*\"this\" + 0.014*\"were\" + 0.014*\"separate\" + 0.014*\"be\" + '\n",
      "  '0.014*\"small\"'),\n",
      " (3,\n",
      "  '0.050*\"this\" + 0.035*\"is\" + 0.035*\"of\" + 0.035*\"you\" + 0.035*\"car\" + '\n",
      "  '0.019*\"know\" + 0.019*\"can\" + 0.019*\"tellme\" + 0.019*\"all\" + '\n",
      "  '0.019*\"production\"'),\n",
      " (4,\n",
      "  '0.012*\"was\" + 0.012*\"car\" + 0.012*\"sports\" + 0.012*\"anyone\" + '\n",
      "  '0.012*\"looked\" + 0.012*\"day\" + 0.012*\"there\" + 0.012*\"door\" + 0.012*\"saw\" + '\n",
      "  '0.012*\"could\"')]\n",
      "*****************************************************************************************************************************\n",
      "\n",
      "Coherence Score of the trained LDA model :  0.7071530299634211\n",
      "\n",
      "*****************************************************************************************************************************\n",
      "\n",
      "****TRAINING THE LDA MODEL FOR MULTIPLE NUMBER OF TOPICS****\n",
      "\n",
      "*****************************************************************************************************************************\n",
      "\n",
      "****CALCULATING THE COHERENCE SCORE AND OPTIMAL NUMBER OF TOPICS FOR THE BEST MODEL OBTAINED****\n",
      "\n",
      "Coherence score of the best LDA model :  0.5881666412568529\n",
      "Optimal number of topics of the best LDA model :  9\n",
      "\n",
      "*****************************************************************************************************************************\n",
      "\n",
      "****PREDICTING NEW INSTANCES BASED ON BEST LDA MODEL****\n",
      "[(0,\n",
      "  '0.011*\"the\" + 0.011*\"poll\" + 0.011*\"clock\" + 0.011*\"have\" + 0.011*\"and\" + '\n",
      "  '0.011*\"of\" + 0.011*\"kuo\" + 0.011*\"upgrade\" + 0.011*\"with\" + 0.011*\"add\"'),\n",
      " (1,\n",
      "  '0.011*\"the\" + 0.011*\"thanks\" + 0.011*\"poll\" + 0.011*\"to\" + 0.011*\"clock\" + '\n",
      "  '0.011*\"so\" + 0.011*\"add\" + 0.011*\"you\" + 0.011*\"answered\" + 0.011*\"kuo\"'),\n",
      " (2,\n",
      "  '0.011*\"clock\" + 0.011*\"the\" + 0.011*\"of\" + 0.011*\"poll\" + 0.011*\"have\" + '\n",
      "  '0.011*\"kuo\" + 0.011*\"washington\" + 0.011*\"this\" + 0.011*\"upgrade\" + '\n",
      "  '0.011*\"add\"'),\n",
      " (3,\n",
      "  '0.034*\"sinks\" + 0.034*\"usage\" + 0.034*\"per\" + 0.034*\"hour\" + 0.034*\"of\" + '\n",
      "  '0.034*\"the\" + 0.034*\"floppy\" + 0.034*\"functionality\" + 0.034*\"next\" + '\n",
      "  '0.034*\"be\"'),\n",
      " (4,\n",
      "  '0.064*\"of\" + 0.064*\"washington\" + 0.064*\"their\" + 0.034*\"have\" + 0.034*\"si\" '\n",
      "  '+ 0.034*\"number\" + 0.034*\"edu\" + 0.034*\"posting\" + 0.034*\"shared\" + '\n",
      "  '0.034*\"host\"'),\n",
      " (5,\n",
      "  '0.064*\"the\" + 0.034*\"knowledge\" + 0.034*\"please\" + 0.034*\"upgrade\" + '\n",
      "  '0.034*\"and\" + 0.034*\"havent\" + 0.034*\"this\" + 0.034*\"guy\" + 0.034*\"done\" + '\n",
      "  '0.034*\"base\"'),\n",
      " (6,\n",
      "  '0.011*\"especially\" + 0.011*\"summarizing\" + 0.011*\"in\" + 0.011*\"two\" + '\n",
      "  '0.011*\"with\" + 0.011*\"day\" + 0.011*\"and\" + 0.011*\"floppies\" + 0.011*\"will\" '\n",
      "  '+ 0.011*\"days\"'),\n",
      " (7,\n",
      "  '0.064*\"speed\" + 0.064*\"experiences\" + 0.034*\"poll\" + 0.034*\"for\" + '\n",
      "  '0.034*\"please\" + 0.034*\"heat\" + 0.034*\"procedure\" + 0.034*\"cards\" + '\n",
      "  '0.034*\"message\" + 0.034*\"attained\"'),\n",
      " (8,\n",
      "  '0.064*\"final\" + 0.064*\"clock\" + 0.034*\"guy\" + 0.034*\"call\" + '\n",
      "  '0.034*\"keywords\" + 0.034*\"shelley\" + 0.034*\"reports\" + 0.034*\"qvfo\" + '\n",
      "  '0.034*\"article\" + 0.034*\"organization\"')]\n"
     ]
    }
   ],
   "source": [
    "A = fit_lda()\n",
    "A.main_func(arr,arr1,5,20, 20, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyPTYInG0jomQCmHk4ETy0TP",
   "collapsed_sections": [],
   "name": "Final_submission.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
